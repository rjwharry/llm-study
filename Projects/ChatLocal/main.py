from langchain_community.llms import HuggingFaceEndpoint
from langchain_community.chat_models.huggingface import ChatHuggingFace
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.runnables.history import RunnableWithMessageHistory
from utils import get_session_history, print_msg, StreamingHandler, refresh_msg
from dotenv import load_dotenv
import streamlit as st
import os

load_dotenv()

st.set_page_config(page_title="ChatLlama", page_icon="ğŸš€")
st.title("ğŸš€ ChatLlama")

if "store" not in st.session_state:
    st.session_state["store"] = dict()

with st.sidebar:
    session_id = st.text_input("Session ID", placeholder="Enter Session ID")
    if st.button("reload"):
        refresh_msg(session_id)

# í˜„ì¬ ì„¸ì…˜ì˜ ëŒ€í™” ê¸°ë¡ ì¶œë ¥
print_msg(session_id)


if user_input := st.chat_input("ë©”ì„¸ì§€ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”."):
    # ì‚¬ìš©ìê°€ ì…ë ¥í•œ ë‚´ìš©
    st.chat_message("user").write(f"{user_input}")

    # AI ë‹µë³€
    with st.chat_message("assistant"):
        stream_handler = StreamingHandler(st.empty())
        # LLM ì •ì˜
        llm = HuggingFaceEndpoint(
            repo_id=os.environ["MODEL_ID"],
            max_new_tokens=2048,
            temperature=0.1,
            stop_sequences=[
                "<|eot_id|>"
            ],  # stop tokenì„ ë„£ì–´ì¤˜ì•¼ ë‹µë³€ì—ì„œ í•´ë‹¹ í† í°ì´ í¬í•¨ë˜ì§€ ì•ŠìŒ
        )
        model = ChatHuggingFace(llm=llm, streaming=True, callbacks=[stream_handler])

        # system, history, ê·¸ë¦¬ê³  ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ prompt êµ¬ì„±
        prompt = ChatPromptTemplate.from_messages(
            [
                ("system", "ì§ˆë¬¸ì— ì§§ê³  ê°„ê²°í•˜ê²Œ ëŒ€ë‹µí•´ì£¼ì„¸ìš”."),
                MessagesPlaceholder(variable_name="history"),
                ("human", "{question}"),
            ]
        )
        chain = prompt | model

        chain_with_memory = RunnableWithMessageHistory(
            chain,
            get_session_history,  # BaseChatMessageHistory ê°ì²´ë¥¼ ë°˜í™˜í•˜ëŠ” callable í•¨ìˆ˜
            input_messages_key="question",
            history_messages_key="history",
        )

        chain_with_memory.invoke(
            {"question": user_input},
            # session id ì„¤ì •
            config={"configurable": {"session_id": session_id}},
        )
        # st.session_state["messages"].append(ChatMessage(role="assistant", content=msg))
