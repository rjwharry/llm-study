{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meta-llama/Meta-Llama-3-8B-Instruct\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "print(os.environ[\"MODEL_ID\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:02<00:00,  1.39it/s]\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.llms.huggingface_pipeline import HuggingFacePipeline\n",
    "hf = HuggingFacePipeline.from_model_id(\n",
    "    model_id=os.environ[\"MODEL_ID\"],\n",
    "    task=\"text-generation\",\n",
    "    model_kwargs={\"device_map\": \"auto\"},\n",
    "    pipeline_kwargs={\"max_new_tokens\": 512},\n",
    "    # device=0,\n",
    "    device_map=\"auto\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:02<00:00,  1.50it/s]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "tokenizer = AutoTokenizer.from_pretrained(os.environ[\"MODEL_ID\"])\n",
    "model = AutoModelForCausalLM.from_pretrained(os.environ[\"MODEL_ID\"])\n",
    "pipe = pipeline(\"text-generation\", model=model, tokenizer=tokenizer, max_new_tokens=512, device_map=\"auto\")\n",
    "hf = HuggingFacePipeline(pipeline=pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer the following question in Korean.\n",
      "#Question: \n",
      "대한민국의 수도는 어디야?\n",
      "\n",
      "#Answer:  서울입니다.\n",
      "\n",
      "#Translation: \n",
      "The capital of South Korea is Seoul. |  |\n",
      "|  |\n",
      "\n",
      "### 5. Vocabulary\n",
      "\n",
      "* 수도 (sodae) - capital\n",
      "* 서울 (seoul) - Seoul\n",
      "* 대한민국 (daehanminguk) - South Korea\n",
      "* 어디야 (eodieya) - where is\n",
      "* 있습니다 (issneun-da) - is\n",
      "\n",
      "### 6. Grammar\n",
      "\n",
      "* Where is...? (어디야...) - This is a question asking for the location of something.\n",
      "*...입니다 (issneun-da) - This is a verb ending indicating that the sentence is a statement.\n",
      "\n",
      "### 7. Exercises\n",
      "\n",
      "* Fill in the blank: 대한민국의 수도는 _______________________입니다.\n",
      "* Answer: 서울입니다.\n",
      "* Write your own question: _______________________________________의 수도는 어디야? (e.g. France, Japan, etc.)\n",
      "* Answer: _______________________________________입니다.\n",
      "\n",
      "### 8. Cultural Notes\n",
      "\n",
      "* Seoul is the capital and largest city of South Korea.\n",
      "* Seoul is known for its vibrant culture, rich history, and modern architecture.\n",
      "* The city is home to many famous landmarks, including the Gyeongbokgung Palace, Bukchon Hanok Village, and Myeong-dong shopping district.\n",
      "\n",
      "### 9. Pronunciation\n",
      "\n",
      "* 수도 (sodae) - soo-doh\n",
      "* 서울 (seoul) - soo-ul\n",
      "* 대한민국 (daehanminguk) - dah-hahn-meeng-gook\n",
      "* 어디야 (eodieya) - oh-dee-yah\n",
      "* 있습니다 (issneun-da) - ee-seh-nee-tah\n",
      "\n",
      "### 10. Fun Facts\n",
      "\n",
      "* Seoul is one of the most populous cities in the world, with over 10 million people.\n",
      "* The city has a rich history, dating back over 2,000 years to the Baekje Kingdom.\n",
      "* Seoul is known for its fashion and beauty trends, and is often referred to as the \"beauty capital\" of Asia.\n",
      "\n",
      "### 11. Conclusion\n",
      "\n",
      "In this lesson, you learned how to ask and answer questions about the capital of South Korea. You also learned some new vocabulary and grammar, and got to practice your pronunciation. Don't forget to practice regularly to improve your Korean skills! |  |\n",
      "|  |\n",
      "\n",
      "## References\n",
      "\n",
      "* Korean Language Proficiency Test (KLPT) Official Guide\n",
      "* Korean Class 101\n",
      "* Duolingo Korean Course\n",
      "* Naver Dictionary\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "template = \"\"\"Answer the following question in Korean.\n",
    "#Question: \n",
    "{question}\n",
    "\n",
    "#Answer: \"\"\"  # 질문과 답변 형식을 정의하는 템플릿\n",
    "prompt = PromptTemplate.from_template(template)  # 템플릿을 사용하여 프롬프트 객체 생성\n",
    "\n",
    "# 프롬프트와 언어 모델을 연결하여 체인 생성\n",
    "chain = prompt | hf | StrOutputParser()\n",
    "\n",
    "question = \"대한민국의 수도는 어디야?\"  # 질문 정의\n",
    "\n",
    "print(\n",
    "    chain.invoke({\"question\": question})\n",
    ")  # 체인을 호출하여 질문에 대한 답변 생성 및 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-study",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
