{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ConversationKGMemory\n",
    "- 지식 그래프를 활용하여 정보를 저장하고 불러온다.\n",
    "- 이를 통해 LLM 모델이 서로 다른 개체 간의 관계를 이해하는데 도움을 주고, 복잡한 연결망과 역사적 맥락을 기반으로 대응하는 능력을 향상시킨다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meta-llama/Meta-Llama-3-8B-Instruct\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "print(os.environ[\"MODEL_ID\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationKGMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_models.huggingface import ChatHuggingFace\n",
    "from langchain_community.llms import HuggingFaceEndpoint\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "\n",
    "# llm = HuggingFaceEndpoint(\n",
    "#     repo_id=os.environ[\"MODEL_ID\"], \n",
    "#     max_new_tokens=1024,\n",
    "#     temperature=0.1,\n",
    "#     huggingfacehub_api_token=os.environ[\"HF_API_KEY\"],\n",
    "# )\n",
    "# model = ChatHuggingFace(llm=llm)\n",
    "model = ChatOllama(model=\"mistral:7b\")\n",
    "# model = ChatOllama(model=\"gemma:7b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationKGMemory(llm=model, return_messages=True)\n",
    "memory.save_context({\"input\": \"say hi to sam\"}, {\"output\": \"who is sam\"})\n",
    "memory.save_context({\"input\": \"sam is a friend\"}, {\"output\": \"okay\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': []}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({\"input\": \"who is sam\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts.prompt import PromptTemplate\n",
    "from langchain.chains import ConversationChain\n",
    "\n",
    "template = \"\"\"The following is a friendly conversation between a human and an AI. \n",
    "The AI is talkative and provides lots of specific details from its context. \n",
    "If the AI does not know the answer to a question, it truthfully says it does not know. \n",
    "The AI ONLY uses information contained in the \"Relevant Information\" section and does not hallucinate.\n",
    "\n",
    "Relevant Information:\n",
    "\n",
    "{history}\n",
    "\n",
    "Conversation:\n",
    "Human: {input}\n",
    "AI:\"\"\"\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"history\", \"input\"], template=template)\n",
    "\n",
    "conversation_with_kg = ConversationChain(\n",
    "    llm=model, prompt=prompt, memory=ConversationKGMemory(llm=model)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': \"My name is Teddy. I'm Software Engineer. Shirley is a coworker of mine, and she's a new designer at our company.\",\n",
       " 'history': '',\n",
       " 'response': \" Hello Teddy, it's nice to meet you! As a software engineer at your company, you work with various teams, including the design team where Shirley, the new designer, belongs. I don't have specific details about Shirley or her previous experience, but I can assist you in understanding design concepts and technologies if needed for your collaboration with her.\\n\\nI can also provide information about design principles such as user-centered design, color theory, typography, and layout techniques. Additionally, I can help answer questions related to software development, programming languages, databases, or other technical topics that might arise during your work together. Let me know if you have any specific inquiries!\"}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_with_kg.invoke(input=\"My name is Teddy. I'm Software Engineer. Shirley is a coworker of mine, and she's a new designer at our company.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'On Shirley: Shirley is a designer. Shirley works at our company.'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_with_kg.memory.load_memory_variables({\"input\": \"who is Shirley?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'Who is Shirley?',\n",
       " 'history': 'On Shirley: Shirley is a designer. Shirley works at our company.',\n",
       " 'response': ' Shirley is a designer who works at our company.'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_with_kg.invoke(input=\"Who is Shirley?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'Who is my coworker?',\n",
       " 'history': '',\n",
       " 'response': \" I don't have any information about your coworkers, as we haven't covered that topic in our context yet. However, if you provide me with more details such as the name of the company or project you are working on, I might be able to help find information related to your coworkers.\"}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_with_kg.invoke(input=\"Who is my coworker?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-study",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
