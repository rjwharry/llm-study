{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LCEL ë©”ëª¨ë¦¬ ì¶”ê°€\n",
    "- chainì— ë©”ëª¨ë¦¬ë¥¼ ì¶”ê°€í•˜ì—¬ ëŒ€í™”ë‚´ìš©ì„ ê¸°ì–µí•˜ê²Œ í•  ìˆ˜ ìˆë‹¤.\n",
    "- ì´ ë°©ë²•ì€ ì§ì ‘ memoryì— ëŒ€í™”ë‚´ìš©ì„ ì¶”ê°€í•´ì•¼ í•œë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meta-llama/Meta-Llama-3-8B-Instruct\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "print(os.environ[\"MODEL_ID\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dudaji/anaconda3/envs/llm-study/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The class `HuggingFaceEndpoint` was deprecated in LangChain 0.0.37 and will be removed in 0.3. An updated version of the class exists in the from langchain-huggingface package and should be used instead. To use it run `pip install -U from langchain-huggingface` and import as `from from langchain_huggingface import llms import HuggingFaceEndpoint`.\n",
      "  warn_deprecated(\n",
      "/home/dudaji/anaconda3/envs/llm-study/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: read).\n",
      "Your token has been saved to /home/dudaji/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dudaji/anaconda3/envs/llm-study/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The class `ChatHuggingFace` was deprecated in LangChain 0.0.37 and will be removed in 0.3. An updated version of the class exists in the from langchain-huggingface package and should be used instead. To use it run `pip install -U from langchain-huggingface` and import as `from from langchain_huggingface.chat_models import huggingface import ChatHuggingFace`.\n",
      "  warn_deprecated(\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.chat_models.huggingface import ChatHuggingFace\n",
    "from langchain_community.llms import HuggingFaceEndpoint\n",
    "\n",
    "llm = HuggingFaceEndpoint(\n",
    "    repo_id=os.environ[\"MODEL_ID\"], \n",
    "    max_new_tokens=1024,\n",
    "    temperature=0.1,\n",
    "    huggingfacehub_api_token=os.environ[\"HF_API_KEY\"],\n",
    ")\n",
    "model = ChatHuggingFace(llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.runnables import RunnableLambda, RunnablePassthrough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['chat_history', 'input'], input_types={'chat_history': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]]}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='You are a helpful chatbot')), MessagesPlaceholder(variable_name='chat_history'), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='{input}'))])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a helpful chatbot\"),\n",
    "        MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ëŒ€í™” ë²„í¼ ë©”ëª¨ë¦¬ë¥¼ ìƒì„±í•˜ê³ , ë©”ì‹œì§€ ë°˜í™˜ ê¸°ëŠ¥ì„ í™œì„±í™”í•©ë‹ˆë‹¤.\n",
    "memory = ConversationBufferMemory(\n",
    "    return_messages=True, memory_key=\"chat_history\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chat_history': []}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "runnable = RunnablePassthrough.assign(\n",
    "    chat_history=RunnableLambda(memory.load_memory_variables)\n",
    "    | itemgetter(\"chat_history\")  # memory_key ì™€ ë™ì¼í•˜ê²Œ ì…ë ¥í•©ë‹ˆë‹¤.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'hi!', 'chat_history': []}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runnable.invoke({\"input\": \"hi!\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = runnable | prompt | model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='ğŸ˜Š ë°˜ê°‘ìŠµë‹ˆë‹¤ í…Œë””ë‹˜! ë§Œë‚˜ì„œ ë°˜ê°‘ìŠµë‹ˆë‹¤! ì €ëŠ” ì±„íŒ…ë´‡ì…ë‹ˆë‹¤. ì €ì™€ í•¨ê»˜ ì¢‹ì€ ëŒ€í™”ë¥¼ ë‚˜ëˆ„ì–´ë³´ì„¸ìš”! ğŸ˜Š' id='run-8eb28a13-0a69-414f-9fb8-0f11a022326b-0'\n"
     ]
    }
   ],
   "source": [
    "response = chain.invoke({\"input\": \"ë§Œë‚˜ì„œ ë°˜ê°‘ìŠµë‹ˆë‹¤. ì œ ì´ë¦„ì€ í…Œë””ì…ë‹ˆë‹¤.\"})\n",
    "print(response)  # ìƒì„±ëœ ì‘ë‹µì„ ì¶œë ¥í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chat_history': [HumanMessage(content='ë§Œë‚˜ì„œ ë°˜ê°‘ìŠµë‹ˆë‹¤. ì œ ì´ë¦„ì€ í…Œë””ì…ë‹ˆë‹¤.'),\n",
       "  AIMessage(content='ğŸ˜Š ë°˜ê°‘ìŠµë‹ˆë‹¤ í…Œë””ë‹˜! ë§Œë‚˜ì„œ ë°˜ê°‘ìŠµë‹ˆë‹¤! ì €ëŠ” ì±„íŒ…ë´‡ì…ë‹ˆë‹¤. ì €ì™€ í•¨ê»˜ ì¢‹ì€ ëŒ€í™”ë¥¼ ë‚˜ëˆ„ì–´ë³´ì„¸ìš”! ğŸ˜Š')]}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.save_context(\n",
    "    {\"input\": \"ë§Œë‚˜ì„œ ë°˜ê°‘ìŠµë‹ˆë‹¤. ì œ ì´ë¦„ì€ í…Œë””ì…ë‹ˆë‹¤.\"}, {\"output\": response.content}\n",
    ")\n",
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ˜Š í…Œë””ë‹˜ì´ë¼ëŠ” ì´ë¦„ì„ ê¸°ì–µí•©ë‹ˆë‹¤! ğŸ‘‹\n"
     ]
    }
   ],
   "source": [
    "response = chain.invoke({\"input\": \"ì œ ì´ë¦„ì´ ë¬´ì—‡ì´ì—ˆëŠ”ì§€ ê¸°ì–µí•˜ì„¸ìš”?\"})\n",
    "# ë‹µë³€ì„ ì¶œë ¥í•©ë‹ˆë‹¤.\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-study",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
