{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG 프로세스\n",
    "## RAG 준비단계\n",
    "![preprocess](./image/rag-1.png)\n",
    "1. 문서 로드(Document Loader): pdf, 웹 문서 등으로부터 문서 내용을 불러온다\n",
    "1. 분할(Splitter): 문서를 작은 chunk 단위로 분할한다\n",
    "1. 임베딩(Embedding): 분할한 chunk를 벡터표현으로 변환한다\n",
    "1. 벡터DB(Vector Store): 임베딩 chunk들을 벡터 DB에 저장한다\n",
    "## RAG 단계\n",
    "![rag](./image/rag-2.png)\n",
    "1. 검색(Retriever): Query를 바탕으로 벡터DB에서 문서를 검색하기 위한 retriever 정의. retriever는 검색 알고리즘으로, dense와 sparse retriever가 있으며, dense는 유사도 기반 검색이고 sparse는 키워드 기반 검색이다.\n",
    "1. 프롬프트(Prompt): RAG를 수행하기 위해 Prompt를 작성한다. Prompt context에 검색한 문서들이 들어가며, Prompt Engineering을 통해 답변 형식을 지정할 수 있다\n",
    "1. LLM: LLM 모델 선정(GPT-4o, Claude3 Opus 등)\n",
    "1. Chain: 위의 모든 단계들을 chain으로 정의하여 최종 output을 얻어낸다 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# API 키를 환경변수로 관리하기 위한 설정 파일\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# API 키 정보 로드\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.llms import HuggingFaceEndpoint\n",
    "from langchain_community.chat_models.huggingface import ChatHuggingFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1단계: PDF 파일 로드\n",
    "loader = PyMuPDFLoader(\"./data/SPRI_AI_Brief_2023년12월호_F.pdf\")\n",
    "docs = loader.load()\n",
    "\n",
    "# 2단계: Text Splitter 정의 및 문서 분할\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=50)\n",
    "splitted_docs = text_splitter.split_documents(docs)\n",
    "\n",
    "# 3단계: 임베딩 정의\n",
    "embedding = HuggingFaceEmbeddings()\n",
    "\n",
    "# 4단계: 벡터DB 생성 및 chunk 임베딩 저장\n",
    "vectorstore = FAISS.from_documents(documents=splitted_docs, embedding=embedding)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tags=['FAISS', 'HuggingFaceEmbeddings'] vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x7049fd89d610>\n",
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: read).\n",
      "Your token has been saved to /home/dudaji/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "# 5단계: retriever 생성\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "# 단계 6: 프롬프트 생성(Create Prompt)\n",
    "prompt = PromptTemplate.from_template(\n",
    "    \"\"\"You are an assistant for question-answering tasks. \n",
    "Use the following pieces of retrieved context to answer the question. \n",
    "If you don't know the answer, just say that you don't know. \n",
    "Answer in Korean.\n",
    "\n",
    "#Question: \n",
    "{question} \n",
    "#Context: \n",
    "{context} \n",
    "\n",
    "#Answer:\"\"\"\n",
    ")\n",
    "\n",
    "# 단계 7: 언어모델(LLM) 생성\n",
    "llm = HuggingFaceEndpoint(\n",
    "    repo_id=os.environ[\"MODEL_ID\"], \n",
    "    max_new_tokens=2048,\n",
    "    temperature=0.1,\n",
    "    huggingfacehub_api_token=os.environ[\"HF_API_KEY\"],\n",
    ")\n",
    "model = ChatHuggingFace(llm=llm)\n",
    "\n",
    "# 단계 8: 체인(Chain) 생성\n",
    "chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Summary in bullet points:**\n",
      "\n",
      "* 구글은 앤스로픽에 최대 20억 달러 투자에 합의하고 5억 달러를 우선 투자했으며, 앤스로픽은 구글과 클라우드 서비스 사용 계약도 체결\n",
      "* 구글, 마이크로소프트, 아마존은 차세대 AI 모델의 대표 기업인 앤스로픽 및 오픈AI와 협력을 확대하는 추세\n",
      "* 알리바바 클라우드는 최신 LLM ‘통이치엔원 2.0’을 공개하고, 산업별로 특화된 생성 AI 모델을 공개하는 한편, 모델 개발과 애플리케이션 구축 절차를 간소화하는 올인원 AI 모델 구축 플랫폼도 출시\n",
      "* 빌 게이츠는 AI 에이전트가 5년 내 일상언어로 모든 작업을 처리할 수 있는 AI 에이전트가 보급되며 컴퓨터를 사용하는 방식이 완전히 바뀔 것으로 예상\n",
      "* AI 에이전트는 의료와 교육, 생산성, 엔터테인먼트·쇼핑 영역의 서비스 대중화를 주도할 것\n",
      "\n",
      "**Note:** I don't know the answer if it's not mentioned in the provided context.\n"
     ]
    }
   ],
   "source": [
    "# 체인 실행(Run Chain)\n",
    "question = \"Summarize as bullet point\"\n",
    "response = chain.invoke(question)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "삼성 가우스(Samsung Gauss)입니다.\n"
     ]
    }
   ],
   "source": [
    "print(chain.invoke(\"What is the name of AI developed by Samsung?\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-study",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
