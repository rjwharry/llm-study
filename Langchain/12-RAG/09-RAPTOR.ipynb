{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAPTOR (Recursive Abstractive Processing for Tree-Organized Retrieval)\n",
    "![raptor](./image/raptor.png)\n",
    "- Text Chunk를 클러스터링하고, 요약하는 과정을 재귀적으로 반복하여 하단에서 상단으로 점점 더 추상화된 요약을 만드는 트리를 구성하는 방법\n",
    "- 기존 검색 증강은 짧고 연속적인 청크만 사용하므로 긴 컨텍스트를 반영하지 못하는 문제가 있다\n",
    "- LLM 모델 또한 컨텍스트가 길어짐에 따라 성능이 저하된다.\n",
    "- RAPTOR는 긴 문서의 정보를 통합하여, 기존에 검색 증강 방법의 제약을 극복하여 더 좋은 성능을 낼 수 있다\n",
    "## 알고리즘\n",
    "1. 문서 분할\n",
    "1. Chunk 클러스터링\n",
    "1. 클러스터마다 요약. 요약된 결과는 상위 노드가 됨.\n",
    "1. 더이상 클러스터링 할 수 없을 때까지 클러스터링과 요약 과정을 반복하여 트리 생성  \n",
    "\n",
    "클러스터링 성능에 따라 RAPTOR 성능에 크게 좌우될 것으로 보임"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dudaji/anaconda3/envs/llm-study/lib/python3.11/html/parser.py:170: XMLParsedAsHTMLWarning: It looks like you're parsing an XML document using an HTML parser. If this really is an HTML document (maybe it's XHTML?), you can ignore or filter this warning. If it's XML, you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the lxml package installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "  k = self.parse_starttag(i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[825, 4302, 536, 388, 4560, 877, 1789, 758, 659, 67, 1098, 5359, 483, 593, 2063, 2899, 211, 10692, 917, 13253, 3557, 2591, 499, 4671, 825, 549, 594, 454, 5753, 488, 2915, 1519, 2063, 1195, 813, 1098, 1011, 9605, 786, 2216, 1185, 3159]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show(close=None, block=None)>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langchain_community.document_loaders.recursive_url_loader import RecursiveUrlLoader\n",
    "from bs4 import BeautifulSoup as Soup\n",
    "import tiktoken\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def num_tokens_from_string(string: str, encoding_name: str) -> int:\n",
    "    # 주어진 문자열에서 토큰의 개수를 반환합니다.\n",
    "    encoding = tiktoken.get_encoding(encoding_name)\n",
    "    num_tokens = len(encoding.encode(string))\n",
    "    return num_tokens\n",
    "\n",
    "# LCEL 문서 로드\n",
    "url = \"https://python.langchain.com/docs/expression_language/\"\n",
    "loader = RecursiveUrlLoader(\n",
    "    url=url, max_depth=2, base_url=\"https://python.langchain.com\", extractor=lambda x: Soup(x, \"html.parser\").text\n",
    ")\n",
    "docs = loader.load()\n",
    "\n",
    "\n",
    "# PydanticOutputParser를 사용한 LCEL 문서 로드 (기본 LCEL 문서 외부)\n",
    "url = \"https://python.langchain.com/docs/modules/model_io/output_parsers/quick_start\"\n",
    "loader = RecursiveUrlLoader(\n",
    "    url=url, max_depth=1, extractor=lambda x: Soup(x, \"html.parser\").text\n",
    ")\n",
    "docs_pydantic = loader.load()\n",
    "\n",
    "# Self Query를 사용한 LCEL 문서 로드 (기본 LCEL 문서 외부)\n",
    "url = \"https://python.langchain.com/docs/modules/data_connection/retrievers/self_query/\"\n",
    "loader = RecursiveUrlLoader(\n",
    "    url=url, max_depth=1, extractor=lambda x: Soup(x, \"html.parser\").text\n",
    ")\n",
    "docs_sq = loader.load()\n",
    "\n",
    "docs.extend([*docs_pydantic, *docs_sq])\n",
    "docs_texts = [d.page_content for d in docs]\n",
    "\n",
    "# 각 문서에 대한 토큰 수 계산\n",
    "counts = [num_tokens_from_string(d, \"cl100k_base\") for d in docs_texts]\n",
    "print(counts)\n",
    "# 토큰 수의 히스토그램을 그립니다.\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(counts, bins=30, color=\"blue\", edgecolor=\"black\", alpha=0.7)\n",
    "plt.title(\"Token Counts in LCEL Documents\")\n",
    "plt.xlabel(\"Token Count\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.grid(axis=\"y\", alpha=0.75)\n",
    "\n",
    "# 히스토그램을 표시합니다.\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'source': 'https://python.langchain.com/docs/expression_language/', 'content_type': 'text/html; charset=utf-8', 'title': 'LangChain Expression Language (LCEL) | ğŸ¦œï¸�ğŸ”— LangChain', 'description': 'LangChain Expression Language, or LCEL, is a declarative way to easily compose chains together.', 'language': 'en'}\n",
      "{'source': 'https://python.langchain.com/v0.1/docs/use_cases/web_scraping/', 'content_type': 'text/html; charset=utf-8', 'title': 'Web scraping | \\uf8ffü¶úÔ∏è\\uf8ffüîó LangChain', 'description': 'Open In Colab', 'language': 'en'}\n"
     ]
    }
   ],
   "source": [
    "print(docs[0].metadata)\n",
    "print(docs[1].metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': 'https://python.langchain.com/docs/expression_language/',\n",
       " 'content_type': 'text/html; charset=utf-8',\n",
       " 'title': 'LangChain Expression Language (LCEL) | ğŸ¦œï¸�ğŸ”— LangChain',\n",
       " 'description': 'LangChain Expression Language, or LCEL, is a declarative way to easily compose chains together.',\n",
       " 'language': 'en'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_sorted = sorted(docs, key=lambda x: x.metadata[\"source\"])\n",
    "d_sorted[0].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': 'https://python.langchain.com/v0.2/docs/introduction/',\n",
       " 'content_type': 'text/html; charset=utf-8',\n",
       " 'title': 'Introduction | \\uf8ffü¶úÔ∏è\\uf8ffüîó LangChain',\n",
       " 'description': 'LangChain is a framework for developing applications powered by large language models (LLMs).',\n",
       " 'language': 'en'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_reversed = list(reversed(d_sorted))\n",
    "d_reversed[0].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num tokens in all context: 99996\n"
     ]
    }
   ],
   "source": [
    "# 문서 텍스트를 연결합니다.\n",
    "# 문서를 출처 메타데이터 기준으로 정렬합니다.\n",
    "d_sorted = sorted(docs, key=lambda x: x.metadata[\"source\"])\n",
    "d_reversed = list(reversed(d_sorted))  # 정렬된 문서를 역순으로 배열합니다.\n",
    "concatenated_content = \"\\n\\n\\n --- \\n\\n\\n\".join(\n",
    "    [\n",
    "        # 역순으로 배열된 문서의 내용을 연결합니다.\n",
    "        doc.page_content\n",
    "        for doc in d_reversed\n",
    "    ]\n",
    ")\n",
    "print(\n",
    "    \"Num tokens in all context: %s\"  # 모든 문맥에서의 토큰 수를 출력합니다.\n",
    "    % num_tokens_from_string(concatenated_content, \"cl100k_base\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 텍스트 분할을 위한 코드\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "chunk_size_tok = 2000  # 토큰의 청크 크기를 설정합니다.\n",
    "# 재귀적 문자 텍스트 분할기를 초기화합니다. 토큰 인코더를 사용하여 청크 크기와 중복을 설정합니다.\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=chunk_size_tok, chunk_overlap=0\n",
    ")\n",
    "texts_split = text_splitter.split_text(\n",
    "    concatenated_content\n",
    ")  # 주어진 텍스트를 분할합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.embeddings import CacheBackedEmbeddings, OllamaEmbeddings\n",
    "from langchain.storage import LocalFileStore\n",
    "\n",
    "store = LocalFileStore(\"./cache/\")\n",
    "# embd = OllamaEmbeddings(model=\"gemma:7b\")\n",
    "embd = OllamaEmbeddings(model=\"mistral:7b\")\n",
    "cached_embeddings = CacheBackedEmbeddings.from_bytes_store(\n",
    "    embd, store, namespace=os.environ[\"MODEL_ID\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms import HuggingFaceEndpoint\n",
    "from langchain_community.chat_models.huggingface import ChatHuggingFace\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "\n",
    "# llm = HuggingFaceEndpoint(\n",
    "#     repo_id=os.environ[\"MODEL_ID\"], \n",
    "#     max_new_tokens=2048,\n",
    "#     temperature=0.1,\n",
    "#     huggingfacehub_api_token=os.environ[\"HF_API_KEY\"],\n",
    "#     streaming=True,\n",
    "#     callbacks=[StreamingStdOutCallbackHandler()],\n",
    "# )\n",
    "# model = ChatHuggingFace(llm=llm)\n",
    "model = ChatOllama(model=\"mistral:7b\")\n",
    "# model = ChatOllama(model=\"gemma:7b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dudaji/anaconda3/envs/llm-study/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from typing import Dict, List, Optional, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import umap\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "RANDOM_SEED = 42  # 재현성을 위한 고정된 시드 값\n",
    "\n",
    "def global_cluster_embeddings(\n",
    "    embeddings: np.ndarray,\n",
    "    dim: int,\n",
    "    n_neighbors: Optional[int] = None,\n",
    "    metric: str = \"cosine\",\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    UMAP을 사용하여 임베딩의 전역 차원 축소를 수행합니다.\n",
    "\n",
    "    매개변수:\n",
    "    - embeddings: numpy 배열로 된 입력 임베딩.\n",
    "    - dim: 축소된 공간의 목표 차원.\n",
    "    - n_neighbors: 선택 사항; 각 점을 고려할 이웃의 수.\n",
    "                   제공되지 않으면 임베딩 수의 제곱근으로 기본 설정됩니다.\n",
    "    - metric: UMAP에 사용할 거리 측정 기준.\n",
    "\n",
    "    반환값:\n",
    "    - 지정된 차원으로 축소된 임베딩의 numpy 배열.\n",
    "    \"\"\"\n",
    "    if n_neighbors is None:\n",
    "        n_neighbors = int((len(embeddings) - 1) ** 0.5)\n",
    "    return umap.UMAP(\n",
    "        n_neighbors=n_neighbors, n_components=dim, metric=metric\n",
    "    ).fit_transform(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def local_cluster_embeddings(\n",
    "    embeddings: np.ndarray, dim: int, num_neighbors: int = 10, metric: str = \"cosine\"\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    임베딩에 대해 지역 차원 축소를 수행합니다. 이는 일반적으로 전역 클러스터링 이후에 사용됩니다.\n",
    "\n",
    "    매개변수:\n",
    "    - embeddings: numpy 배열로서의 입력 임베딩.\n",
    "    - dim: 축소된 공간의 목표 차원 수.\n",
    "    - num_neighbors: 각 점에 대해 고려할 이웃의 수.\n",
    "    - metric: UMAP에 사용할 거리 측정 기준.\n",
    "\n",
    "    반환값:\n",
    "    - 지정된 차원으로 축소된 임베딩의 numpy 배열.\n",
    "    \"\"\"\n",
    "    return umap.UMAP(\n",
    "        n_neighbors=num_neighbors, n_components=dim, metric=metric\n",
    "    ).fit_transform(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optimal_clusters(\n",
    "    embeddings: np.ndarray, max_clusters: int = 50, random_state: int = RANDOM_SEED\n",
    ") -> int:\n",
    "    \"\"\"\n",
    "    가우시안 혼합 모델(Gaussian Mixture Model)을 사용하여 베이지안 정보 기준(BIC)을 통해 최적의 클러스터 수를 결정합니다.\n",
    "\n",
    "    매개변수:\n",
    "    - embeddings: numpy 배열로서의 입력 임베딩.\n",
    "    - max_clusters: 고려할 최대 클러스터 수.\n",
    "    - random_state: 재현성을 위한 시드.\n",
    "\n",
    "    반환값:\n",
    "    - 발견된 최적의 클러스터 수를 나타내는 정수.\n",
    "    \"\"\"\n",
    "    max_clusters = min(\n",
    "        max_clusters, len(embeddings)\n",
    "    )  # 최대 클러스터 수와 임베딩의 길이 중 작은 값을 최대 클러스터 수로 설정\n",
    "    n_clusters = np.arange(1, max_clusters)  # 1부터 최대 클러스터 수까지의 범위를 생성\n",
    "    bics = []  # BIC 점수를 저장할 리스트\n",
    "    for n in n_clusters:  # 각 클러스터 수에 대해 반복\n",
    "        gm = GaussianMixture(\n",
    "            n_components=n, random_state=random_state\n",
    "        )  # 가우시안 혼합 모델 초기화\n",
    "        gm.fit(embeddings)  # 임베딩에 대해 모델 학습\n",
    "        bics.append(gm.bic(embeddings))  # 학습된 모델의 BIC 점수를 리스트에 추가\n",
    "    return n_clusters[np.argmin(bics)]  # BIC 점수가 가장 낮은 클러스터 수를 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GMM_cluster(embeddings: np.ndarray, threshold: float, random_state: int = 0):\n",
    "    \"\"\"\n",
    "    확률 임계값을 기반으로 가우시안 혼합 모델(GMM)을 사용하여 임베딩을 클러스터링합니다.\n",
    "\n",
    "    매개변수:\n",
    "    - embeddings: numpy 배열로서의 입력 임베딩.\n",
    "    - threshold: 임베딩을 클러스터에 할당하기 위한 확률 임계값.\n",
    "    - random_state: 재현성을 위한 시드.\n",
    "\n",
    "    반환값:\n",
    "    - 클러스터 레이블과 결정된 클러스터 수를 포함하는 튜플.\n",
    "    \"\"\"\n",
    "    n_clusters = get_optimal_clusters(embeddings)  # 최적의 클러스터 수를 구합니다.\n",
    "    # 가우시안 혼합 모델을 초기화합니다.\n",
    "    gm = GaussianMixture(n_components=n_clusters, random_state=random_state)\n",
    "    gm.fit(embeddings)  # 임베딩에 대해 모델을 학습합니다.\n",
    "    probs = gm.predict_proba(\n",
    "        embeddings\n",
    "    )  # 임베딩이 각 클러스터에 속할 확률을 예측합니다.\n",
    "    # 임계값을 초과하는 확률을 가진 클러스터를 레이블로 선택합니다.\n",
    "    labels = [np.where(prob > threshold)[0] for prob in probs]\n",
    "    return labels, n_clusters  # 레이블과 클러스터 수를 반환합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_clustering(\n",
    "    embeddings: np.ndarray,\n",
    "    dim: int,\n",
    "    threshold: float,\n",
    ") -> List[np.ndarray]:\n",
    "    \"\"\"\n",
    "    임베딩에 대해 차원 축소, 가우시안 혼합 모델을 사용한 클러스터링, 각 글로벌 클러스터 내에서의 로컬 클러스터링을 순서대로 수행합니다.\n",
    "\n",
    "    매개변수:\n",
    "    - embeddings: numpy 배열로 된 입력 임베딩입니다.\n",
    "    - dim: UMAP 축소를 위한 목표 차원입니다.\n",
    "    - threshold: GMM에서 임베딩을 클러스터에 할당하기 위한 확률 임계값입니다.\n",
    "\n",
    "    반환값:\n",
    "    - 각 임베딩의 클러스터 ID를 포함하는 numpy 배열의 리스트입니다.\n",
    "    \"\"\"\n",
    "    if len(embeddings) <= dim + 1:\n",
    "        # 데이터가 충분하지 않을 때 클러스터링을 피합니다.\n",
    "        return [np.array([0]) for _ in range(len(embeddings))]\n",
    "\n",
    "    # 글로벌 차원 축소\n",
    "    reduced_embeddings_global = global_cluster_embeddings(embeddings, dim)\n",
    "    # 글로벌 클러스터링\n",
    "    global_clusters, n_global_clusters = GMM_cluster(\n",
    "        reduced_embeddings_global, threshold\n",
    "    )\n",
    "\n",
    "    all_local_clusters = [np.array([]) for _ in range(len(embeddings))]\n",
    "    total_clusters = 0\n",
    "\n",
    "    # 각 글로벌 클러스터를 순회하며 로컬 클러스터링 수행\n",
    "    for i in range(n_global_clusters):\n",
    "        # 현재 글로벌 클러스터에 속하는 임베딩 추출\n",
    "        global_cluster_embeddings_ = embeddings[\n",
    "            np.array([i in gc for gc in global_clusters])\n",
    "        ]\n",
    "\n",
    "        if len(global_cluster_embeddings_) == 0:\n",
    "            continue\n",
    "        if len(global_cluster_embeddings_) <= dim + 1:\n",
    "            # 작은 클러스터는 직접 할당으로 처리\n",
    "            local_clusters = [np.array([0]) for _ in global_cluster_embeddings_]\n",
    "            n_local_clusters = 1\n",
    "        else:\n",
    "            # 로컬 차원 축소 및 클러스터링\n",
    "            reduced_embeddings_local = local_cluster_embeddings(\n",
    "                global_cluster_embeddings_, dim\n",
    "            )\n",
    "            local_clusters, n_local_clusters = GMM_cluster(\n",
    "                reduced_embeddings_local, threshold\n",
    "            )\n",
    "\n",
    "        # 로컬 클러스터 ID 할당, 이미 처리된 총 클러스터 수를 조정\n",
    "        for j in range(n_local_clusters):\n",
    "            local_cluster_embeddings_ = global_cluster_embeddings_[\n",
    "                np.array([j in lc for lc in local_clusters])\n",
    "            ]\n",
    "            indices = np.where(\n",
    "                (embeddings == local_cluster_embeddings_[:, None]).all(-1)\n",
    "            )[1]\n",
    "            for idx in indices:\n",
    "                all_local_clusters[idx] = np.append(\n",
    "                    all_local_clusters[idx], j + total_clusters\n",
    "                )\n",
    "\n",
    "        total_clusters += n_local_clusters\n",
    "\n",
    "    return all_local_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed(texts):\n",
    "    # 텍스트 문서 목록에 대한 임베딩을 생성합니다.\n",
    "    #\n",
    "    # 이 함수는 `embd` 객체가 존재한다고 가정하며, 이 객체는 텍스트 목록을 받아 그 임베딩을 반환하는 `embed_documents` 메소드를 가지고 있습니다.\n",
    "    #\n",
    "    # 매개변수:\n",
    "    # - texts: List[str], 임베딩할 텍스트 문서의 목록입니다.\n",
    "    #\n",
    "    # 반환값:\n",
    "    # - numpy.ndarray: 주어진 텍스트 문서들에 대한 임베딩 배열입니다.\n",
    "    text_embeddings = embd.embed_documents(\n",
    "        texts\n",
    "    )  # 텍스트 문서들의 임베딩을 생성합니다.\n",
    "    text_embeddings_np = np.array(text_embeddings)  # 임베딩을 numpy 배열로 변환합니다.\n",
    "    return text_embeddings_np  # 임베딩된 numpy 배열을 반환합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_cluster_texts(texts):\n",
    "    \"\"\"\n",
    "    텍스트 목록을 임베딩하고 클러스터링하여, 텍스트, 그들의 임베딩, 그리고 클러스터 라벨이 포함된 DataFrame을 반환합니다.\n",
    "\n",
    "    이 함수는 임베딩 생성과 클러스터링을 단일 단계로 결합합니다. 임베딩에 대해 클러스터링을 수행하는 `perform_clustering` 함수의 사전 정의된 존재를 가정합니다.\n",
    "\n",
    "    매개변수:\n",
    "    - texts: List[str], 처리될 텍스트 문서의 목록입니다.\n",
    "\n",
    "    반환값:\n",
    "    - pandas.DataFrame: 원본 텍스트, 그들의 임베딩, 그리고 할당된 클러스터 라벨이 포함된 DataFrame입니다.\n",
    "    \"\"\"\n",
    "    text_embeddings_np = embed(texts)  # 임베딩 생성\n",
    "    cluster_labels = perform_clustering(\n",
    "        text_embeddings_np, 10, 0.1\n",
    "    )  # 임베딩에 대해 클러스터링 수행\n",
    "    df = pd.DataFrame()  # 결과를 저장할 DataFrame 초기화\n",
    "    df[\"text\"] = texts  # 원본 텍스트 저장\n",
    "    df[\"embd\"] = list(text_embeddings_np)  # DataFrame에 리스트로 임베딩 저장\n",
    "    df[\"cluster\"] = cluster_labels  # 클러스터 라벨 저장\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fmt_txt(df: pd.DataFrame) -> str:\n",
    "    \"\"\"\n",
    "    DataFrame에 있는 텍스트 문서를 단일 문자열로 포맷합니다.\n",
    "\n",
    "    매개변수:\n",
    "    - df: 'text' 열에 포맷할 텍스트 문서가 포함된 DataFrame.\n",
    "\n",
    "    반환값:\n",
    "    - 모든 텍스트 문서가 특정 구분자로 결합된 단일 문자열.\n",
    "    \"\"\"\n",
    "    unique_txt = df[\"text\"].tolist()  # 'text' 열의 모든 텍스트를 리스트로 변환\n",
    "    return \"--- --- \\n --- --- \".join(\n",
    "        unique_txt\n",
    "    )  # 텍스트 문서들을 특정 구분자로 결합하여 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_cluster_summarize_texts(\n",
    "    texts: List[str], level: int\n",
    ") -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    텍스트 목록에 대해 임베딩, 클러스터링 및 요약을 수행합니다. 이 함수는 먼저 텍스트에 대한 임베딩을 생성하고,\n",
    "    유사성을 기반으로 클러스터링을 수행한 다음, 클러스터 할당을 확장하여 처리를 용이하게 하고 각 클러스터 내의 내용을 요약합니다.\n",
    "\n",
    "    매개변수:\n",
    "    - texts: 처리할 텍스트 문서 목록입니다.\n",
    "    - level: 처리의 깊이나 세부 사항을 정의할 수 있는 정수 매개변수입니다.\n",
    "\n",
    "    반환값:\n",
    "    - 두 개의 데이터프레임을 포함하는 튜플:\n",
    "      1. 첫 번째 데이터프레임(`df_clusters`)은 원본 텍스트, 그들의 임베딩, 그리고 클러스터 할당을 포함합니다.\n",
    "      2. 두 번째 데이터프레임(`df_summary`)은 각 클러스터에 대한 요약, 지정된 세부 수준, 그리고 클러스터 식별자를 포함합니다.\n",
    "    \"\"\"\n",
    "\n",
    "    # 텍스트를 임베딩하고 클러스터링하여 'text', 'embd', 'cluster' 열이 있는 데이터프레임을 생성합니다.\n",
    "    df_clusters = embed_cluster_texts(texts)\n",
    "\n",
    "    # 클러스터를 쉽게 조작하기 위해 데이터프레임을 확장할 준비를 합니다.\n",
    "    expanded_list = []\n",
    "\n",
    "    # 데이터프레임 항목을 문서-클러스터 쌍으로 확장하여 처리를 간단하게 합니다.\n",
    "    for index, row in df_clusters.iterrows():\n",
    "        for cluster in row[\"cluster\"]:\n",
    "            expanded_list.append(\n",
    "                {\"text\": row[\"text\"], \"embd\": row[\"embd\"], \"cluster\": cluster}\n",
    "            )\n",
    "\n",
    "    # 확장된 목록에서 새 데이터프레임을 생성합니다.\n",
    "    expanded_df = pd.DataFrame(expanded_list)\n",
    "\n",
    "    # 처리를 위해 고유한 클러스터 식별자를 검색합니다.\n",
    "    all_clusters = expanded_df[\"cluster\"].unique()\n",
    "\n",
    "    print(f\"--Generated {len(all_clusters)} clusters--\")\n",
    "\n",
    "    # 요약\n",
    "    template = \"\"\"여기 LangChain 표현 언어 문서의 하위 집합이 있습니다.\n",
    "    \n",
    "    LangChain 표현 언어는 LangChain에서 체인을 구성하는 방법을 제공합니다.\n",
    "    \n",
    "    제공된 문서의 자세한 요약을 제공하십시오.\n",
    "    \n",
    "    문서:\n",
    "    {context}\n",
    "    \"\"\"\n",
    "    prompt = ChatPromptTemplate.from_template(template)\n",
    "    chain = prompt | model | StrOutputParser()\n",
    "\n",
    "    # 각 클러스터 내의 텍스트를 요약을 위해 포맷팅합니다.\n",
    "    summaries = []\n",
    "    for i in all_clusters:\n",
    "        df_cluster = expanded_df[expanded_df[\"cluster\"] == i]\n",
    "        formatted_txt = fmt_txt(df_cluster)\n",
    "        summaries.append(chain.invoke({\"context\": formatted_txt}))\n",
    "\n",
    "    # 요약, 해당 클러스터 및 레벨을 저장할 데이터프레임을 생성합니다.\n",
    "    df_summary = pd.DataFrame(\n",
    "        {\n",
    "            \"summaries\": summaries,\n",
    "            \"level\": [level] * len(summaries),\n",
    "            \"cluster\": list(all_clusters),\n",
    "        }\n",
    "    )\n",
    "\n",
    "    return df_clusters, df_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recursive_embed_cluster_summarize(\n",
    "    texts: List[str], level: int = 1, n_levels: int = 3\n",
    ") -> Dict[int, Tuple[pd.DataFrame, pd.DataFrame]]:\n",
    "    \"\"\"\n",
    "    지정된 레벨까지 또는 고유 클러스터의 수가 1이 될 때까지 텍스트를 재귀적으로 임베딩, 클러스터링, 요약하여\n",
    "    각 레벨에서의 결과를 저장합니다.\n",
    "\n",
    "    매개변수:\n",
    "    - texts: List[str], 처리할 텍스트들.\n",
    "    - level: int, 현재 재귀 레벨 (1에서 시작).\n",
    "    - n_levels: int, 재귀의 최대 깊이.\n",
    "\n",
    "    반환값:\n",
    "    - Dict[int, Tuple[pd.DataFrame, pd.DataFrame]], 재귀 레벨을 키로 하고 해당 레벨에서의 클러스터 DataFrame과 요약 DataFrame을 포함하는 튜플을 값으로 하는 사전.\n",
    "    \"\"\"\n",
    "    results = {}  # 각 레벨에서의 결과를 저장할 사전\n",
    "\n",
    "    # 현재 레벨에 대해 임베딩, 클러스터링, 요약 수행\n",
    "    df_clusters, df_summary = embed_cluster_summarize_texts(texts, level)\n",
    "\n",
    "    # 현재 레벨의 결과 저장\n",
    "    results[level] = (df_clusters, df_summary)\n",
    "\n",
    "    # 추가 재귀가 가능하고 의미가 있는지 결정\n",
    "    unique_clusters = df_summary[\"cluster\"].nunique()\n",
    "    if level < n_levels and unique_clusters > 1:\n",
    "        # 다음 레벨의 재귀 입력 텍스트로 요약 사용\n",
    "        new_texts = df_summary[\"summaries\"].tolist()\n",
    "        next_level_results = recursive_embed_cluster_summarize(\n",
    "            new_texts, level + 1, n_levels\n",
    "        )\n",
    "\n",
    "        # 다음 레벨의 결과를 현재 결과 사전에 병합\n",
    "        results.update(next_level_results)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Generated 7 clusters--\n"
     ]
    }
   ],
   "source": [
    "# 트리 구축\n",
    "leaf_texts = docs_texts  # 문서 텍스트를 리프 텍스트로 설정\n",
    "results = recursive_embed_cluster_summarize(\n",
    "    # leaf_texts, level=1, n_levels=3\n",
    "    leaf_texts, level=7, n_levels=3\n",
    ")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "{7: (                                                 text  \\\n",
      "0   \\n\\n\\n\\n\\nLangChain Expression Language (LCEL)...   \n",
      "1   \\n\\n\\n\\n\\nAdvantages of LCEL | ü¶úÔ∏èüîó Lan...   \n",
      "2   \\n\\n\\n\\n\\nComponents | ğŸ¦œï¸�ğŸ”— LangChain\\n...   \n",
      "3   \\n\\n\\n\\n\\nProviders | ü¶úÔ∏èüîó LangChain\\n\\...   \n",
      "4   \\n\\n\\n\\n\\nWeb scraping | ü¶úÔ∏èüîó LangChain...   \n",
      "5   \\n\\n\\n\\n\\nSecurity | ğŸ¦œï¸�ğŸ”— LangChain\\n\\n...   \n",
      "6   \\n\\n\\n\\n\\nTemplates | ü¶úÔ∏èüîó LangChain\\n\\...   \n",
      "7   \\n\\n\\n\\n\\nInstallation | ğŸ¦œï¸�ğŸ”— LangChain...   \n",
      "8   \\n\\n\\n\\n\\nGraphs | ğŸ¦œï¸�ğŸ”— LangChain\\n\\n\\n...   \n",
      "9   \\n\\nğŸ¦œï¸�ğŸ”— LangChain\\nSearch ğŸ¦œï¸�ğŸ”— ...   \n",
      "10  \\n\\n\\n\\n\\nIntroduction | ğŸ¦œï¸�ğŸ”— LangChain...   \n",
      "11  \\n\\n\\n\\n\\nQuickstart | ü¶úÔ∏èüîó LangChain\\n...   \n",
      "12  \\n\\n\\n\\n\\nğŸ¦œğŸ› ï¸� LangSmith | ğŸ¦œï¸�ğŸ”— ...   \n",
      "13  \\n\\n\\n\\n\\nSQL | ğŸ¦œï¸�ğŸ”— LangChain\\n\\n\\n\\n\\...   \n",
      "14  \\n\\n\\n\\n\\nIntroduction | ü¶úÔ∏èüîó LangChain...   \n",
      "15  \\n\\n\\n\\n\\nYouTube videos | ü¶úÔ∏èüîó LangCha...   \n",
      "16  \\n\\n\\n\\n\\nGuides | ğŸ¦œï¸�ğŸ”— LangChain\\n\\n\\n...   \n",
      "17  \\n\\n\\n\\n\\nStreaming | ü¶úÔ∏èüîó LangChain\\n\\...   \n",
      "18  \\n\\n\\n\\n\\nQ&A with RAG | ü¶úÔ∏èüîó LangChain...   \n",
      "19  \\n\\n\\n\\n\\nConceptual guide | ü¶úÔ∏èüîó LangC...   \n",
      "20  \\n\\n\\n\\n\\nPeople | ü¶úÔ∏èüîó LangChain\\n\\n\\n...   \n",
      "21  \\n\\n\\n\\n\\nAdd message history (memory) | ü¶úÔ...   \n",
      "22  \\n\\n\\n\\n\\nTutorials | ğŸ¦œï¸�ğŸ”— LangChain\\n\\...   \n",
      "23  \\n\\n\\n\\n\\nRoute logic based on input | ü¶úÔ∏è...   \n",
      "24  \\n\\n\\n\\n\\nLangChain Expression Language (LCEL)...   \n",
      "25  \\n\\n\\n\\n\\nğŸ“• Package Versioning | ğŸ¦œï¸�ğŸ”...   \n",
      "26  \\n\\n\\n\\n\\nChatbots | ğŸ¦œï¸�ğŸ”— LangChain\\n\\n...   \n",
      "27  \\n\\n\\n\\n\\nTool use and agents | ğŸ¦œï¸�ğŸ”— La...   \n",
      "28  \\n\\n\\n\\n\\nü¶úÔ∏èüèì LangServe | ü¶úÔ∏èüîó ...   \n",
      "29  \\n\\n\\n\\n\\nUse cases | ğŸ¦œï¸�ğŸ”— LangChain\\n\\...   \n",
      "30  \\n\\n\\n\\n\\nGet started | ü¶úÔ∏èüîó LangChain\\...   \n",
      "31  \\n\\n\\n\\n\\nParallel: Format data | ü¶úÔ∏èüîó ...   \n",
      "32  \\n\\n\\n\\n\\nIntroduction | ü¶úÔ∏èüîó LangChain...   \n",
      "33  \\n\\n\\n\\n\\nQuery analysis | ü¶úÔ∏èüîó LangCha...   \n",
      "34  \\n\\n\\n\\n\\nPrimitives | ğŸ¦œï¸�ğŸ”— LangChain\\n...   \n",
      "35  \\n\\n\\n\\n\\nIntroduction | ğŸ¦œï¸�ğŸ”— LangChain...   \n",
      "36  \\n\\n\\n\\n\\nExtracting structured output | ü¶úÔ...   \n",
      "37  \\n\\n\\n\\n\\nRunnable interface | ü¶úÔ∏èüîó Lan...   \n",
      "38  \\n\\n\\n\\n\\nWelcome Contributors | ğŸ¦œï¸�ğŸ”— L...   \n",
      "39  \\n\\n\\n\\n\\nFallbacks | ü¶úÔ∏èüîó LangChain\\n\\...   \n",
      "40  \\n\\n\\n\\n\\nQuickstart | ü¶úÔ∏èüîó LangChain\\n...   \n",
      "41  \\n\\n\\n\\n\\nSelf-querying | ü¶úÔ∏èüîó LangChai...   \n",
      "\n",
      "                                                 embd     cluster  \n",
      "0   [4.451562881469727, 4.568757057189941, 9.98282...  [4.0, 4.0]  \n",
      "1   [4.93299674987793, 6.082887649536133, 4.463100...       [0.0]  \n",
      "2   [-1.0781248807907104, 4.208497524261475, 10.37...       [5.0]  \n",
      "3   [-3.402681350708008, 3.9624648094177246, 7.866...       [5.0]  \n",
      "4   [4.745623588562012, 5.547607898712158, 4.24368...       [0.0]  \n",
      "5   [-1.0574777126312256, 2.7213351726531982, 9.11...       [5.0]  \n",
      "6   [-2.8907339572906494, 5.3342084884643555, 6.29...       [2.0]  \n",
      "7   [1.684532880783081, 4.710825443267822, 8.89819...       [4.0]  \n",
      "8   [-1.1775444746017456, 1.6574383974075317, 11.0...       [5.0]  \n",
      "9   [5.280169486999512, 2.021561861038208, 7.62258...       [4.0]  \n",
      "10  [3.7063920497894287, 2.3465416431427, 8.479870...  [5.0, 5.0]  \n",
      "11  [1.5861128568649292, 7.029420852661133, 3.7400...       [2.0]  \n",
      "12  [1.0992435216903687, 4.042975425720215, 11.075...       [1.0]  \n",
      "13  [4.320227146148682, 1.4425914287567139, 11.187...       [5.0]  \n",
      "14  [0.6075807213783264, 6.371564865112305, 6.4857...  [2.0, 2.0]  \n",
      "15  [3.0028114318847656, 5.3503098487854, 4.609107...       [2.0]  \n",
      "16  [1.025128960609436, 1.8337030410766602, 6.6505...       [1.0]  \n",
      "17  [0.7445043325424194, 10.119267463684082, 4.623...       [0.0]  \n",
      "18  [0.9666998386383057, 5.52421236038208, 7.24518...       [6.0]  \n",
      "19  [2.146125316619873, 6.601285457611084, 4.93210...       [2.0]  \n",
      "20  [0.9962486624717712, 5.127518177032471, 4.6943...       [2.0]  \n",
      "21  [0.4624551832675934, 6.242332935333252, 3.0034...       [0.0]  \n",
      "22  [-0.3417090177536011, 0.8881082534790039, 10.1...       [3.0]  \n",
      "23  [3.2271785736083984, 6.52927827835083, 3.86528...       [0.0]  \n",
      "24  [4.451562881469727, 4.568757057189941, 9.98282...  [4.0, 4.0]  \n",
      "25  [2.798846960067749, 7.236181735992432, 11.1866...       [4.0]  \n",
      "26  [1.8170522451400757, 3.8890469074249268, 9.161...       [5.0]  \n",
      "27  [3.811526298522949, -1.013426661491394, 10.512...       [5.0]  \n",
      "28  [-2.4591336250305176, 6.916897296905518, 5.359...       [2.0]  \n",
      "29  [1.3963041305541992, 6.0213775634765625, 10.53...       [1.0]  \n",
      "30  [0.41275209188461304, 4.8205437660217285, 3.60...       [0.0]  \n",
      "31  [-0.9175559878349304, 3.080693006515503, 7.583...       [3.0]  \n",
      "32  [0.6075807213783264, 6.371564865112305, 6.4857...  [2.0, 2.0]  \n",
      "33  [2.601243495941162, 3.498560905456543, 8.60008...       [6.0]  \n",
      "34  [1.0651750564575195, 1.9635779857635498, 12.48...       [4.0]  \n",
      "35  [3.7063920497894287, 2.3465416431427, 8.479870...  [5.0, 5.0]  \n",
      "36  [2.594373941421509, 2.7566447257995605, 8.9877...       [6.0]  \n",
      "37  [0.24465395510196686, 7.043337345123291, 4.187...       [2.0]  \n",
      "38  [0.25537076592445374, 2.6144533157348633, 10.2...       [4.0]  \n",
      "39  [-1.8856488466262817, 7.020641326904297, 2.757...       [0.0]  \n",
      "40  [-3.5017621517181396, -1.363652229309082, 11.2...       [3.0]  \n",
      "41  [1.4541727304458618, 4.924561500549316, 5.8994...       [0.0]  ,                                            summaries  level  cluster\n",
      "0   The text you provided is a documentation page...      7      4.0\n",
      "1   This code demonstrates how to create a self-q...      7      0.0\n",
      "2   Here is a summary of the contents of the prov...      7      5.0\n",
      "3   This is a documentation page for using parall...      7      2.0\n",
      "4   The provided document is a summary of the Lan...      7      1.0\n",
      "5   The documentation page provides a clear and c...      7      6.0\n",
      "6   It looks like you've provided a good overview...      7      3.0)}\n"
     ]
    }
   ],
   "source": [
    "print(len(results))\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "# leaf_texts를 복사하여 all_texts를 초기화합니다.\n",
    "all_texts = leaf_texts.copy()\n",
    "\n",
    "# 각 레벨의 요약을 추출하여 all_texts에 추가하기 위해 결과를 순회합니다.\n",
    "for level in sorted(results.keys()):\n",
    "    # 현재 레벨의 DataFrame에서 요약을 추출합니다.\n",
    "    summaries = results[level][1][\"summaries\"].tolist()\n",
    "    # 현재 레벨의 요약을 all_texts에 추가합니다.\n",
    "    all_texts.extend(summaries)\n",
    "\n",
    "# 이제 all_texts를 사용하여 FAISS vectorstore를 구축합니다.\n",
    "vectorstore = FAISS.from_texts(texts=all_texts, embedding=embd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "DB_INDEX = \"RAPTOR\"\n",
    "\n",
    "# 로컬에 FAISS DB 인덱스가 이미 존재하는지 확인하고, 그렇다면 로드하여 vectorstore와 병합한 후 저장합니다.\n",
    "if os.path.exists(DB_INDEX):\n",
    "    local_index = FAISS.load_local(DB_INDEX, embd)\n",
    "    local_index.merge_from(vectorstore)\n",
    "    local_index.save_local(DB_INDEX)\n",
    "else:\n",
    "    vectorstore.save_local(folder_path=DB_INDEX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retriever 생성\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "# 프롬프트 생성\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "# 문서 포스트 프로세싱\n",
    "\n",
    "\n",
    "def format_docs(docs):\n",
    "    # 문서의 페이지 내용을 이어붙여 반환합니다.\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "\n",
    "# RAG 체인 정의\n",
    "rag_chain = (\n",
    "    # 검색 결과를 포맷팅하고 질문을 처리합니다.\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt  # 프롬프트를 적용합니다.\n",
    "    | model  # 모델을 적용합니다.\n",
    "    | StrOutputParser()  # 문자열 출력 파서를 적용합니다.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The document provides a guide on using Parallel Execution in the LangChain Expression Language (LEL) to execute multiple elements simultaneously, focusing on the `RunnableParallel` class and batch processing for optimized results. It also offers insights into utilizing Large Language Models (LLMs) for information extraction applications, providing three approaches: Tool/Function Calling Mode, JSON Mode, and Prompting Based, with an emphasis on the Tool/Function Calling approach. The documentation includes best practices, a reference application, and additional resources for further learning.\n"
     ]
    }
   ],
   "source": [
    "# 추상적인 질문 실행\n",
    "print(rag_chain.invoke(\"Explain the subject of the whole document\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The documentation provides an overview of the RAG (Retrieval-and-Generation) architecture and its usage for Q&A applications using data from SQL databases or code (e.g., Python). It also introduces LangChain Expression Language (LCEL), which is a declarative way to compose chains together for efficient prototyping and production deployment of RAG applications.\n",
      "\n",
      "Here are some areas where I can provide feedback on this documentation page:\n",
      "\n",
      "1. Clarity and organization: The documentation is well-organized, with clear headings and subheadings that make it easy for users to find the information they need quickly. However, it would be helpful if there were more explanatory text around each section, as some concepts might not be immediately understandable without additional context.\n",
      "2. Terminology: Some terms used in the documentation, such as \"Retrieval-and-Generation\" (RAG), \"LangChain,\" and \"LCEL,\" may be unfamiliar to users who are new to these technologies. It would be helpful if there were brief explanations for each term in the initial sections of the documentation or a glossary of terms at the end.\n",
      "3. Examples and code snippets: The documentation could benefit from more examples and code snippets that demonstrate how to use RAG and LCEL in practice. This would help users better understand how to apply these concepts to their own projects.\n",
      "4. Links and resources: The documentation mentions other resources, such as the community Discord, Twitter, GitHub, and blog, but it would be helpful if there were direct links to these resources within the documentation itself. This would make it easier for users to access relevant information quickly.\n",
      "5. Updates and improvements: It is always useful for users to know when a document has been updated or improved. Adding a \"What's New\" section or version number at the beginning of the documentation would help users determine if they should refer to an older or newer version of the documentation based on their needs.\n",
      "6. Visualization and illustrations: Diagrams or flowcharts that visually represent the RAG architecture and LCEL workflow could be helpful in better understanding these concepts.\n",
      "7. Error handling and troubleshooting: The documentation should include information about common errors users may encounter when working with RAG and LCEL, as well as troubleshooting tips for resolving those issues.\n",
      "\n",
      "Overall, the documentation provides a good starting point for users interested in learning about RAG and LCEL. With some improvements, it could become even more helpful and user-friendly.\n"
     ]
    }
   ],
   "source": [
    "print(rag_chain.invoke(\"Write example python code using PydanticOutputParser\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Self-querying works by creating a retriever that fetches documents based on user queries and specified filters. In Python, this can be achieved using the LangChain library. The retriever consists of two main components: the query constructor chain and the structured query translator. The query constructor processes a user query, generating a StructuredQuery object with both the query term and relevant filters. The structured query translator then translates this generic StructuredQuery into a format compatible with the vector store being used. Here's an example of how to create a self-querying retriever:\n",
      "\n",
      "```python\n",
      "retriever = SelfQueryRetriever(\n",
      "    query_constructor=your_customized_query_constructor,\n",
      "    vectorstore=your_vector_store_instance,\n",
      "    structured_query_translator=ChromaTranslator()  # for Chroma vector store compatibility\n",
      ")\n",
      "\n",
      "results = retriever.invoke(\"Your query here\")\n",
      "for result in results:\n",
      "    print(result)\n",
      "```\n",
      "\n",
      "For more details and examples, refer to the LangChain cookbook or documentation.\n"
     ]
    }
   ],
   "source": [
    "print(rag_chain.invoke(\"Explain how self-query works and write example python code\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-study",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
