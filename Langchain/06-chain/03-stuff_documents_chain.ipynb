{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# StuffDocumentsChain\n",
    "- 문서 목록을 가져와서 모두 프롬프트에 포함시킨 후 LLM에 전달하는 Chain.\n",
    "- 문서가 작고 적은 호출을 할 때 적합한 chain이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meta-llama/Meta-Llama-3-8B-Instruct\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "print(os.environ[\"MODEL_ID\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['context'], messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='You are an expert summarizer. Please summarize the following sentence.')), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context'], template='Please summarize the sentence according to the following request.\\nREQUEST:\\n1. Summarize the main points in bullet points in Korean.2. Each summarized sentence must start with an emoji that fits the meaning of the each sentence.3. Use various emojis to make the summary more interesting.\\n\\nCONTEXT: {context}\\n\\nSUMMARY:'))])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are an expert summarizer. Please summarize the following sentence.\",\n",
    "        ),\n",
    "        (\n",
    "            \"user\",\n",
    "            \"Please summarize the sentence according to the following request.\"\n",
    "            \"\\nREQUEST:\\n\"\n",
    "            \"1. Summarize the main points in bullet points in Korean.\"\n",
    "            \"2. Each summarized sentence must start with an emoji that fits the meaning of the each sentence.\"\n",
    "            \"3. Use various emojis to make the summary more interesting.\"\n",
    "            \"\\n\\nCONTEXT: {context}\\n\\nSUMMARY:\",\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.documents.base.Document'>\n",
      "문서의 수: 1\n",
      "\n",
      "[메타데이터]\n",
      "\n",
      "{'source': 'data/news.txt'}\n",
      "\n",
      "========= [앞부분] 미리보기 =========\n",
      "\n",
      "제목: \n",
      "AI2, 상업 활용까지 자유로운 '진짜' 오픈 소스 LLM '올모' 출시\n",
      "\n",
      "내용:\n",
      "앨런AI연구소(AI2)가 완전한 오픈 소스 대형언어모델(LLM) '올모(OLMo)’를 출시했다. 데이터 수집, 학습, 배포의 전 과정을 투명하게 공개한 데다 상업적 사용까지 허용한 진정한 의미의 오픈 소스 LLM이라는 평가다.\n",
      "벤처비트는 1일(현지시간) 비영리 민간 AI 연구기관인 AI2가 ‘최초의 진정한 오픈 소스 LLM 및 프레임워크’라고 소개한 ‘올모’를 출시했다고 보도했다. \n",
      "이에 따르면 올모는 모델 코드와 모델 가중치뿐만 아니라 훈련 코드, 훈련 데이터, 관련 툴킷 및 평가 툴킷도 제공한다. 이를 통해 모델이 어떻게 구축되었는지 심층적으로 분석, LLM의 작동 방식과 응답을 생성하는 원리를 더 잘 이해할 수 있다. \n",
      "올모 프레임워크는 70억 매개변수의 ‘올모 7B’ 등 4가지 변형 모델과 10억 매개변수의 ‘올모 1B’ 모델을 제공한다. 모델들은 훈련 데이터를 생성하는 코드를 포함해 \n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "\n",
    "loader = TextLoader(\"data/news.txt\")\n",
    "docs = loader.load()\n",
    "print(type(docs[0]))\n",
    "print(f\"문서의 수: {len(docs)}\\n\")\n",
    "print(\"[메타데이터]\\n\")\n",
    "print(docs[0].metadata)\n",
    "print(\"\\n========= [앞부분] 미리보기 =========\\n\")\n",
    "print(docs[0].page_content[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: read).\n",
      "Your token has been saved to /home/dudaji/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from langchain.callbacks.base import BaseCallbackHandler\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_community.chat_models.huggingface import ChatHuggingFace\n",
    "from langchain_community.llms import HuggingFaceEndpoint\n",
    "\n",
    "class MyCallbackHandler(BaseCallbackHandler):\n",
    "    def on_llm_new_token(self, token: str, **kwargs) -> None:\n",
    "        print(f\"{token}\", end=\"\", flush=True)\n",
    "\n",
    "\n",
    "llm = HuggingFaceEndpoint(\n",
    "    repo_id=os.environ[\"MODEL_ID\"], \n",
    "    max_new_tokens=1024,\n",
    "    temperature=0.1,\n",
    "    streaming=True,\n",
    "    callbacks=[MyCallbackHandler()],\n",
    "    huggingfacehub_api_token=os.environ[\"HF_API_KEY\"],\n",
    ")\n",
    "model = ChatHuggingFace(llm=llm)\n",
    "\n",
    "chain = create_stuff_documents_chain(model, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is the summary in Korean, with each point starting with an emoji:\n",
      "\n",
      "• 🎉 올모(OLMo)는 앨런AI연구소(AI2)가 출시한 완전한 오픈 소스 대형언어모델(LLM)입니다.\n",
      "• 💡 올모는 모델 코드, 모델 가중치, 훈련 코드, 훈련 데이터, 관련 툴킷, 평가 툴킷 등을 제공하여 모델의 구축 과정을 심층적으로 분석할 수 있습니다.\n",
      "• 📊 올모 프레임워크에는 4가지 변형 모델(올모 7B, 올모 1B 등)이 포함되어 있습니다.\n",
      "• 💻 프레임워크에는 추론 코드, 훈련 지표, 훈련 로그, 모델 가중치, 평가 제품군 등이 포함되어 있습니다.\n",
      "• 📈 올모는 상업적 활용에 제한이 없습니다. 아파치 2.0 라이선스에 따라 사용할 수 있습니다.\n",
      "• 🤔 AI2는 올모를 통해 연구자들이 안전하고 신뢰할 수 있는 차세대 시스템을 구축하는 데 중요한 LLM 과학을 연구할 수 있게 될 것이라고 말합니다.\n",
      "• 📊 성능 면에서는 올모가 상업용 제품과 동등한 성능을 보여주는 것으로 나타났습니다.\n",
      "• 🚫 다만 비영어권 언어에 대한 낮은 품질과 약한 코드 생성 기능과 같은 제약 사항이 있습니다.\n",
      "• 💪 AI2는 올모를 계속해서 향상할 것이라고 말합니다.\n",
      "\n",
      "Note: The summary is based on the provided text and may not include all the details.<|eot_id|>\n"
     ]
    }
   ],
   "source": [
    "print(chain.invoke({\"context\": docs}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-study",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
